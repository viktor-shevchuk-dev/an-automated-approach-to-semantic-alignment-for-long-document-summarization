{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sentencepiece\n",
    "from transformers import pipeline, AutoTokenizer, set_seed\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import contractions  \n",
    "import gensim\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from vizualization import utils_split_sentences, display_string_matching\n",
    "from scrape import get_English_laws_pagination_urls, retrieve_english_laws_and_abstracts_from_pagination_pages\n",
    "from summarizers.extractive import summarize_with_extractive_methods\n",
    "from summarizers.zero_shot_abstractive import save_abstractive_summaries\n",
    "from evaluate_generated_summaries import evaluate_generated_summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English_laws_pagination_urls = await get_English_laws_pagination_urls()\n",
    "# English_laws_pagination_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await retrieve_english_laws_and_abstracts_from_pagination_pages(English_laws_pagination_urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_with_extractive_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare y_test and predicted\n",
    "# from IPython.core.display import display, HTML\n",
    "# match = display_string_matching(dtf_test[\"y\"][i], predicted, both=True, sentences=False,\n",
    "#                                 titles=[\"Real Summary\", \"Predicted Summary\"])\n",
    "\n",
    "# display(HTML(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explainability\n",
    "# from IPython.core.display import display, HTML\n",
    "# match = display_string_matching(dtf_test[\"text\"][i], predicted , both=True, sentences=True,\n",
    "#                                 titles=[\"Full Text\", \"Predicted Summary\"])\n",
    "\n",
    "# display(HTML(match))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstractive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed(1)\n",
    "# gpt2_model_name = \"gpt2-xl\"\n",
    "# pipe = pipeline(\"text-generation\", model=gpt2_model_name, max_new_tokens=64)\n",
    "# gpt2_query = \"summarize:\\n\"+ sample_text \n",
    "# pipe_out = pipe(gpt2_query, clean_up_tokenization_spaces=True)\n",
    "# test3 = sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :])\n",
    "# test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_model_name = \"t5-large\"\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)\n",
    "# t5_pipe = pipeline(\"summarization\", model=t5_model_name, tokenizer=t5_tokenizer)\n",
    "# t5_pipe_out = t5_pipe(sample_text)\n",
    "# sent_tokenize(t5_pipe_out[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegasus_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# pegasus_tokenizer = AutoTokenizer.from_pretrained(pegasus_model_name)\n",
    "# pegasus_pipe = pipeline(\"summarization\", model=pegasus_model_name, tokenizer=pegasus_tokenizer)\n",
    "# pegasus_pipe_out = pegasus_pipe(sample_text)\n",
    "# sent_tokenize(pegasus_pipe_out[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bart_model_name = \"facebook/bart-large-cnn\"\n",
    "# bart_tokenizer = AutoTokenizer.from_pretrained(bart_model_name, model_max_length=512) # the model won't accept an input sequence longer than 512 tokens\n",
    "# bart_pipe = pipeline(\"summarization\", model=bart_model_name, tokenizer=bart_tokenizer)\n",
    "# bart_pipe_out = bart_pipe(text, max_length=512) # it won't produce a summary longer than 512 tokens.\n",
    "# sent_tokenize(bart_pipe_out[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_abstractive_summaries(model_name=\"gpt2-xl\", max_token_number=512, max_new_tokens=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_abstractive_summaries(model_name=\"facebook/bart-large-cnn\", max_token_number=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_abstractive_summaries(model_name=\"t5-large\", max_token_number=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_abstractive_summaries(model_name=\"google/pegasus-cnn_dailymail\", max_token_number=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_generated_summaries()\n",
    "# evaluate_generated_summaries(\"zero_shot_abstractive\", \"gpt2_xl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d569fefa4ff5660fa9c2f1dfa382b3700d307fde3813ab35bb4c9cb0d80f7a0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
